{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install kagglehub\n",
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac868d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a870f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + \"/fashion-mnist_train.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=30000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253091d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_df.iloc[:, 1:].values\n",
    "y = sample_df.iloc[:, :1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70cd1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59baed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e92ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = st_scaler.fit_transform(X_train)\n",
    "X_test = st_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70e891",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dataset class\n",
    "\n",
    "class FashionMNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        print(type(features))\n",
    "        print(type(labels))\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a059c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(X_train, y_train)\n",
    "test_dataset = FashionMNISTDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da17bcb",
   "metadata": {},
   "source": [
    "# OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers, neurons_per_layer):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "\n",
    "            layers.append(\n",
    "                nn.Linear(input_dim , neurons_per_layer)\n",
    "            )\n",
    "            input_dim = neurons_per_layer\n",
    "\n",
    "        layers.append(\n",
    "            nn.Linear(neurons_per_layer, output_dim)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.BatchNorm1d(128), # batch normalization layer to stabilize and accelerate training, applied before activation functions, \n",
    "                                 #       128 - is the number of features from the previous layer, 1d as we have 1 dimensional data\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2), # using dropout to prevent overfitting, dropout rate of 20%, used to prevent overfitting, applied after activation functions\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(16, 10),\n",
    "            # nn.Softmax(dim=1) - softmax is not required in PyTorch as it is included in the CrossEntropyLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "\n",
    "def objective_function(trial):\n",
    "\n",
    "    # next hyperparameter values\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 5, step=1, log=False)\n",
    "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 10, 128, step=8, log=False)\n",
    "\n",
    "\n",
    "    # model init\n",
    "    input_dim = 784\n",
    "    output_dim = 10\n",
    "\n",
    "    class \n",
    "\n",
    "\n",
    "\n",
    "    # params init\n",
    "\n",
    "    # training loop\n",
    "\n",
    "    # evaluation\n",
    "\n",
    "\n",
    "    # return accuracy\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
