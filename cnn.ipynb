{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ec89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /home/jatin/Documents/code/pytorch/.venv/lib/python3.12/site-packages (from scikit-learn) (2.4.0)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.16.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "# ! pip install optuna\n",
    "# ! pip install torch\n",
    "# ! pip install pandas\n",
    "# ! pip install numpy\n",
    "# ! pip install matplotlib\n",
    "# ! pip install kagglehub\n",
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fde8426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jatin/Documents/code/pytorch/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a31029",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/kaggle/input/fashionmnist\"\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aecf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + \"/fashion-mnist_train.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=60000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052be3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_df.iloc[:, 1:].values\n",
    "y = sample_df.iloc[:, :1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ce46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = st_scaler.fit_transform(X_train)\n",
    "X_test = st_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f2968",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7045e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dataset class\n",
    "\n",
    "class FashionMNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        \n",
    "        self.features = torch.tensor(features, dtype=torch.float32).reshape(-1, 1, 28, 28) # converted 1D 784 rows into 28x28 2D rows, \n",
    "                                                                                        # 1 states that its a grayscale image, -1 is the batch size\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65442f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(X_train, y_train)\n",
    "test_dataset = FashionMNISTDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cedd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # convolutions and pooling layer\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = input_features,\n",
    "                out_channels = 32,\n",
    "                kernel_size = 3,\n",
    "                padding = 'same' \n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 64,\n",
    "                kernel_size = 3,\n",
    "                padding = 'same' \n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*7*7 , 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "epochs = 100\n",
    "\n",
    "model = CNNModel(1).to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"----------- Epoch {epoch+1}/{epochs} -----------\")\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        \n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = loss_function(outputs, batch_labels.squeeze())\n",
    "        total_epoch_loss.append(loss.item())\n",
    "\n",
    "        # backprop\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\" avg epoch loss: {sum(total_epoch_loss)/len(total_epoch_loss)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043923d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# evaluation\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# return accuracy\n",
    "\n",
    "total = 0\n",
    "correct = 0 \n",
    "i = 1\n",
    "cnt =0\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "\n",
    "        cnt +=1\n",
    "        \n",
    "        # move data to gpu\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "            \n",
    "        test_outputs = model(batch_features)\n",
    "\n",
    "        _, predicted = torch.max(test_outputs, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (predicted == batch_labels.squeeze()).sum().item()\n",
    "\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
